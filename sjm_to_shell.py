'''
 sjm to shell : A script conversion tool

  2024.1.15  by Janice Lai
                copilot: GPT3.5
'''

from collections import defaultdict
import argparse

def process_sjm_file(file_path):
	'''
	读取sjm文件中的job，将每个job中的 name 和 cmd 内容存储进一个字典中
	- 输入: file_path (sjm文件名)
	- 输出: 内容解析字典 (name为key，cmd内容为value，其中cmd内容可能有多个，value内容用列表来储存)
	
	Read jobs from the sjm file and store the name and cmd content of each job in a dictionary.
	- Input: file_path (sjm file name)
	- Output: Parsed dictionary (where name serves as the key, and cmd content as the value.The cmd content may contain multiple entries, and the values are stored in a list).

	'''
	job_dict = {}  # 字典用于存储提取的信息

	with open(file_path, 'r') as file:
		lines = file.readlines()

	i = 0
	while i < len(lines):
		line = lines[i].strip()
		# 首先判断该行是否存在job_begin，若存在，则往下读取name，读到name后提取name后的字符串存入key；读到cmd后提取cmd后的字符串存入value
		# 找到包含 "job_begin" 的行
		if "job_begin" in line:
			i += 1
			name = ''
			while i < len(lines):
				inner_line = lines[i].strip()
				# 提取 "name" 行的信息
				if inner_line.startswith("name"):
					name = inner_line.split(" ", 1)[1]
					job_dict[name] = []
				# 提取 "cmd" 行的信息
				elif inner_line.startswith("cmd"):
					cmd = inner_line.split(" ", 1)[1]
					if name:
						job_dict[name].append(cmd)
					else:
						# 存在错误，退出程序
						print(f'#! name not found!, on line {i+1}.')
						exit(1)
				# 如果遇到 "job_end" 行，结束内层循环
				elif inner_line == "job_end":
					break
				
				i += 1
		i += 1

	return job_dict


def parse_config_file(file_path):
	'''
	读取和整理sjm文件中不同order之间的依赖关系,将结果存入一个字典中
	- 输入: file_path (sjm文件名)
	- 输出: 内容解析字典 (key为 father job(不受依赖的job），value为 son job(依赖 father job的job))

	Read and organize the dependency relationships between different orders in the sjm file,and store the results in a dictionary.
	- Input: file_path (sjm file name)
	- Output: Parsed dictionary (where the key is the father job (jobs without dependencies),and the value is the son job (jobs dependent on the father job)).

	'''
	dependencies = defaultdict(list)
	with open(file_path, 'r') as file:
		for line in file:
			line = line.strip()
			if 'order' in line:
				if 'after' in line:
					son, father = line.split('after')
					son = son.strip('order')
					dependencies[father.strip()].append(son.strip())
				elif 'before' in line:
					father, son = line.split('before')
					father = father.strip('order')
					dependencies[father.strip()].append(son.strip())
	return dependencies



# 拓扑排序算法：具有约束性, 需要考虑先后关系）
def jobs_parallel(jobs):
	'''
	拓扑排序算法：将sjm文件中的job按order依赖关系排成可并行执行的顺序
	- 输入：通过 parse_config_file() 函数整理后生成的order关系结果字典 dependencies
	- 输出：拓扑排序结果列表
	jobs_parallel()是基于拓扑排序顺序算法的并行算法，本方法只使用了字典和列表来存储数据，在gpt给出的方法基础上用另一种巧妙的方式来存储动态数据。
	并行顺序执行是指当job之间没有依赖关系时，将没有依赖关系的jobs并行执行，当存在依赖关系时，顺序执行。
	本方法输出的job顺序结果可通过参数选择，生成单通道的顺序执行脚本或并行的执行脚本。使用并行的执行脚本，可提高代码执行的效率。

	Topological Sorting Algorithm : Arrange jobs from the sjm file based on order dependencies for parallel execution.
	- Input: The dependencies result dictionary generated through the parse_config_file() function.
	- Output: List of topologically sorted results.
	The jobs_parallel() function is a parallel algorithm based on the topological sorting order algorithm.
	This method uses only dictionaries and lists to store data, employing a clever approach to store dynamic data based on the original GPT method.
	Parallel sequential execution refers to the scenario where jobs without dependencies are executed in parallel, while jobs with dependencies are executed sequentially.
	The job order results generated by this method can be customized through parameters to generate either single-channel sequential execution scripts or parallel execution scripts.
	Using parallel execution scripts can enhance code execution efficiency.
	'''
  # 初始化 in_degree 入度字典 {边:入度量}; q 待执行任务列表; sort_out 任务排序输出列表
	in_degree, q, sort_out = {}, [], []

	# 遍历 jobs 图的所有 边 ( -> to 节点), 计算每一个 边 的入度 (多少个节点指向它)
	for job in jobs.values():
		for p in job:
			if in_degree.get(p):
				in_degree[p] += 1
			else:
				in_degree[p] = 1

	# 遍历 jobs 的 节点 (From 部分), 找出没有依赖关系的节点 (入度为0)
	for node in jobs.keys():
		# 如果该节点 没有人指向它 (没有入度), 则在 q 队列插入该节点
		if not in_degree.get(node):
			q.append(node)

	# 从 q 待执行任务列表按先后顺序, 取出没有依赖关系的节点
	# !!! 这里的 q 列表会在循环执行过程中不断被添加内容的 !!!
	while q:
		sort_out.append(q)
		# 设置一个临时列表，用来存储当前这一阶段的节点的依赖任务入度为0的任务
		t = []
		for node in q:
			# 如果该节点不存在 from 节点, 则添加一个空的进去
			if not jobs.get(node):
				jobs[node] = []

			# 遍历该 节点 所有的 依赖任务 (即 node -> 指向的下游), 将它们的入度 -1 （表示已经完成了)
			for job in jobs[node]:
				in_degree[job] -= 1
				# 如果 入度为0 表示所有依赖已经实现, 可以执行任务, 因此加入 q 列表
				if in_degree[job] == 0:
					t.append(job)
		
		# 将q重置为下一阶段的节点
		q = t

	# 通过两个数量比较，判断是否存在环
	# 求sort_out的总长度（计算上内嵌的列表）
	total_len = sum(len(sublist) for sublist in sort_out)
	if total_len != len(jobs):
		raise ValueError("There is a cycle in the dependencies")

	return sort_out


def main():
	'''
	将sjm文件输出成单通道顺序或并行顺序的shell脚本
	- 输入：-i sjm文件名 -o 输出的shell文件名 -f 选择输出shell文件使用单通道顺序执行(fun_1)或并行顺序执行(fun_11) -s 选择输出shell文件(sh)或bash文件(bash)
	- 输出：可执行的结果shell文件

	Convert sjm file into a shell script for single-channel sequential or parallel sequential execution.
	- Input: -i sjm file name, -o output shell file name, 
			-f choose between single-channel sequential execution (fun_1) or parallel sequential execution (fun_11), 
			-s choose between outputting a shell script (sh) or a bash script (bash).
	- Output: Executable result shell script.

	'''
	# 使用 argparse 解析命令行参数
	parser = argparse.ArgumentParser(description='sjm to shell : A script conversion tool')
	parser.add_argument('-i', '--input', required=True, help='sjm file name')
	parser.add_argument('-o', '--output', required=True, help='shell file name')
	parser.add_argument('-f', '--function', default='fun_11', choices=['fun_1', 'fun_11'], help='Specify the function to execute')
	parser.add_argument('-s', '--shell', default='sh', choices=['sh', 'bash'], help='Specify the shell to execute')
	args = parser.parse_args()

	file_path = args.input
	selected_function = args.function
	selected_sh = args.shell
	# result_dict存放job name 与 cmd 之间的对应关系
	result_dict = process_sjm_file(file_path)
	# 解析sjm文件中的order依赖关系
	dependencies = parse_config_file(file_path)
	# 执行拓扑排序
	sort_out = jobs_parallel(dependencies)

	# 根据参数, 采用 并行 或 串行 方式输出 
	if selected_function == 'fun_1':
		print("Executing fun_1:single-channel execution.")
		with open(args.output, 'w') as file:
		# 输出排序结果
			for list in sort_out:
				for node in list:
					if result_dict[node]:
						if selected_sh == 'sh':
							for i in result_dict[node]:
								file.write(i + '\n')
						elif selected_sh =='bash':
							for i in result_dict[node]:
								file.write('ba' + i + '\n')
						else :
							print("Invalid function specified. Please choose either 'sh' or 'bash' .")

	elif selected_function == 'fun_11':
		print("Executing fun_11:parallel execution.")
		sort_out = jobs_parallel(dependencies)
		with open(args.output, 'w') as file:
			# 输出排序结果
			for list in sort_out:
				for node in list:
					if result_dict[node]:
						if selected_sh == 'sh':
							for i in result_dict[node]:
								file.write(i + ' &' '\n')
						elif selected_sh =='bash':
							for i in result_dict[node]:
								file.write('ba' + i + ' &' '\n')
						else :
							print("Invalid function specified. Please choose either 'sh' or 'bash' .")
				file.write('wait\n')
		
	else:
		print("Invalid function specified. Please choose either 'fun_1' or 'fun_2' .")

if __name__ == "__main__":
	main()





